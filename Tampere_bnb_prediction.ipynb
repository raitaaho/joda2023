{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44bd9f2",
   "metadata": {},
   "source": [
    "# TampereBNB Listings - Price Prediction\n",
    "<p> Get ready for an exhilarating data science adventure! In this exciting assignment, you will dive into the world of TampereBNB, the popular platform for short-term accommodation rentals. \n",
    "    <br>\n",
    "    Your mission? To analyze data from this platform and use your data science skills to predict missing prices for some of the listings, using the tools mentioned in the following cell. </p>\n",
    "<br>\n",
    "\n",
    "## Instructions\n",
    "- Train a regression model of your choice on predicting the listing prices of the training data. \n",
    "- Use the trained model to get the price predictions for the listings in the testing data.\n",
    "- Store the resulting dataframe as a pickled (out.pkl) file. \n",
    "\n",
    "**NOTE: The code snippets for loading the data files and outputting the resulting dataframe, are provided. Do not update them.**\n",
    "\n",
    "\n",
    "#### Accessing the dataset\n",
    "To facilitate your work, we have created two separate training and testing TampereBNB csv files, located within the `data/` folder. Make sure the path to the files is the same, before submitting your solution.\n",
    "\n",
    "#### TODO\n",
    "\n",
    "- You are expected to predict prices for the listings on the testing data by using the following libraries (Besides the built-in python modules, specific libraries can be included upon request):\n",
    "    - scikit-learn (sklearn)\n",
    "    - pandas\n",
    "    - numpy\n",
    "    \n",
    "- Store your predictions as a dataframe with the attribute `Hinta` (case sensitive).\n",
    "- Save the dataframe in a pickle file, `out.pkl` (case sensitive).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a6736-b034-4917-ba6b-307c8ee7e2e0",
   "metadata": {},
   "source": [
    "## Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "319c09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b0df0",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "617b703b-c52a-475a-95b2-4b04a05f4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !MAKE SURE TO NOT CHANGE THE CODE WITHIN THIS CELL!. \n",
    "# Instead, put the data files within a folder named 'data' such that the paths would work.\n",
    "training_df = pd.read_csv('./data/Tampere_BNB_training_listing.csv')\n",
    "testing_df = pd.read_csv('./data/Tampere_BNB_testing_listing.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80621696-0dd5-4484-a08b-a61939612717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_highest_floor(row):\n",
    "    if row['Krs'].split('/')[0] == row['Krs'].split('/')[1]:\n",
    "        if int(row['Krs'].split('/')[0]) > 1:\n",
    "            return \"on\"\n",
    "        else:\n",
    "            return \"ei\"\n",
    "    else:\n",
    "        return \"ei\"\n",
    "    \n",
    "def correct_floor(row):\n",
    "    return min(int(row['Krs'].split('/')[1]), int(row['Krs'].split('/')[0]))\n",
    "\n",
    "def huoneisto_string_cleaner(row):\n",
    "    char_replacements = {\n",
    "        \" \": \"\",\n",
    "        \"+\": \",\",\n",
    "        \"x\": \"\",\n",
    "        \".\": \"\",\n",
    "        \"(\": \"\",\n",
    "        \")\": \"\",\n",
    "        \"/\": \",\"\n",
    "    }\n",
    "    string = row['Huoneisto'].translate(str.maketrans(char_replacements))\n",
    "    cleaned_string = string.replace(\"lasitettu\", '').replace(\"lasit\", '').replace(\"las\", '')\n",
    "    return cleaned_string\n",
    "\n",
    "def label_sauna(row):\n",
    "    huoneisto_tokens = row['Huoneisto'].lower().split(\",\")\n",
    "    sauna_tokens = ['s', 'sauna']\n",
    "    for token in huoneisto_tokens:\n",
    "        if token in sauna_tokens:\n",
    "            return \"on\"\n",
    "        if \"sauna\" in token:\n",
    "            return \"on\"\n",
    "    return \"ei\"\n",
    "\n",
    "def label_parveke(row):\n",
    "    huoneisto_tokens = row['Huoneisto'].lower().split(\",\")\n",
    "    parveke_tokens = ['p', 'parv', 'parveke']\n",
    "    for token in huoneisto_tokens:\n",
    "        if token in parveke_tokens:\n",
    "            return \"on\"\n",
    "        if \"parv\" in token:\n",
    "            return \"on\"\n",
    "    return \"ei\"\n",
    "\n",
    "def label_kattoterassi(row):\n",
    "    huoneisto_tokens = row['Huoneisto'].lower().split(\",\")\n",
    "    for token in huoneisto_tokens:\n",
    "        if \"kattoterassi\" in token:\n",
    "            return \"on\"\n",
    "    return \"ei\"\n",
    "\n",
    "def label_huoneiden_lkm(row):\n",
    "    string_to_int = {\n",
    "        \"yksiö\": 1,\n",
    "        \"kaksi\": 2,\n",
    "        \"kolme\": 3,\n",
    "        \"neljä\": 4\n",
    "    }\n",
    "    asunnon_tyyppi_tokens = row['Asunnon tyyppi'].lower().split()\n",
    "    for token in asunnon_tyyppi_tokens:\n",
    "        if token in list(string_to_int.keys()):\n",
    "            return string_to_int[token]\n",
    "        \n",
    "def get_distance_from_trainstation(row):\n",
    "    rautatieasema = (61.4986261803628, 23.775149167944846)\n",
    "    current = (float(row['Leveysaste']), float(row['Pituusaste']))\n",
    "    return geodesic(current, rautatieasema).km\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a6f7f",
   "metadata": {},
   "source": [
    "## Data Cleaning (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3441433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data for further processing\n",
    "testing_df['Huoneisto'] = testing_df['Huoneisto'].str.lower()\n",
    "testing_df['Huoneisto'] = testing_df.apply(huoneisto_string_cleaner, axis=1)\n",
    "testing_df['Krs'] = testing_df['Krs'].fillna('1/1')\n",
    "testing_df['Krs'] = testing_df['Krs'].str.replace(\"-\", '')\n",
    "testing_df['Hissi'] = testing_df['Hissi'].fillna('ei')\n",
    "testing_df['Kunto'] = testing_df['Kunto'].fillna('tyyd.')\n",
    "\n",
    "training_df['Huoneisto'] = training_df['Huoneisto'].str.lower()\n",
    "training_df['Huoneisto'] = training_df.apply(huoneisto_string_cleaner, axis=1)\n",
    "training_df['Krs'] = training_df['Krs'].fillna('1/1')\n",
    "training_df['Krs'] = training_df['Krs'].str.replace(\"-\", '')\n",
    "training_df['Hissi'] = training_df['Hissi'].fillna('ei')\n",
    "training_df['Kunto'] = training_df['Kunto'].fillna('tyyd.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75480dc-8ad4-4fd3-bdbc-fc906926af3c",
   "metadata": {},
   "source": [
    "## Feature Engineering (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "321dbb26-2549-436b-82ad-712fe41bea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering/extraction/discovery to extract features new from the raw data.\n",
    "testing_df['Krs'] = testing_df.apply(correct_floor, axis=1)\n",
    "testing_df['Sauna'] = testing_df.apply(label_sauna, axis=1)\n",
    "testing_df['Parveke'] = testing_df.apply(label_parveke, axis=1)\n",
    "testing_df['Kattoterassi'] = testing_df.apply(label_kattoterassi, axis=1)\n",
    "testing_df['Huoneiden lkm'] = testing_df.apply(label_huoneiden_lkm, axis=1)\n",
    "testing_df['Etäisyys rautatieasemalta'] = testing_df.apply(get_distance_from_trainstation, axis=1)\n",
    "testing_df = testing_df.drop(columns=['Huoneisto', 'Krs', 'Asunnon tyyppi', 'Pituusaste', 'Leveysaste'])\n",
    "\n",
    "training_df['Krs'] = training_df.apply(correct_floor, axis=1)\n",
    "training_df['Sauna'] = training_df.apply(label_sauna, axis=1)\n",
    "training_df['Parveke'] = training_df.apply(label_parveke, axis=1)\n",
    "training_df['Kattoterassi'] = training_df.apply(label_kattoterassi, axis=1)\n",
    "training_df['Huoneiden lkm'] = training_df.apply(label_huoneiden_lkm, axis=1)\n",
    "training_df['Etäisyys rautatieasemalta'] = training_df.apply(get_distance_from_trainstation, axis=1)\n",
    "training_df = training_df.drop(columns=['Huoneisto', 'Krs', 'Asunnon tyyppi', 'Pituusaste', 'Leveysaste'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9c136-891d-4b77-a45e-4466dba98153",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc9144c7-d090-44e7-9ed8-82875c3e205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your prediction solution here.\n",
    "# Make sure to store your predictions in the 'Hinta' attribute of the testing dataframe.\n",
    "# By default, the following assignment will initialize the 'Hinta' column with the given constant.\n",
    "testing_df[\"Hinta\"] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "171ed566-6fcf-46bb-9129-0863d6cd50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Combine training_df and testing_df into single dataframe\n",
    "combined_df = pd.concat([training_df, testing_df], axis=0)\n",
    "\n",
    "# Reset the index to ensure uniqueness\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "\n",
    "# Process the data for one-hot encoding\n",
    "cat_cols = ['Kaupunginosa', 'Talot.', 'Hissi', 'Kunto', 'Sauna', 'Parveke', 'Kattoterassi']\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "combined_df_cat = encoder.fit_transform(combined_df[cat_cols])\n",
    "combined_df_cat = pd.DataFrame(combined_df_cat, columns=encoder.get_feature_names_out(cat_cols))\n",
    "\n",
    "# concatenate the encoded categorical columns with the original dataframe\n",
    "combined_df = pd.concat([combined_df.drop(cat_cols, axis=1), combined_df_cat], axis=1)\n",
    "\n",
    "# Separate training and test data again \n",
    "train_data = combined_df[:len(training_df)]\n",
    "test_data = combined_df[len(training_df):]\n",
    "\n",
    "# Define features- and target columns\n",
    "features = [col for col in train_data.columns if col != 'Hinta']\n",
    "target = 'Hinta'\n",
    "\n",
    "# Create a LinearRegression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the LinearRegression model\n",
    "model.fit(train_data[features], train_data[target])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_data[features])\n",
    "\n",
    "# Add column with prediction to original testing_df \n",
    "testing_df['Hinta'] = predictions.round(0).astype(np.int64)\n",
    "\n",
    "# Save into file out.csv\n",
    "testing_df.to_csv('out.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4272e4-06c7-49b5-b7cd-977a3965ba8b",
   "metadata": {},
   "source": [
    "## Store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06c9bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !MAKE SURE TO NOT CHANGE THE CODE WITHIN THIS CELL!. \n",
    "testing_df.to_pickle(\"out.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
